{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use niwrap3912 conda environment\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import map_coordinates\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sample_at_points(volume, points, affine):\n",
    "    \"\"\"Sample volume intensities at given points using trilinear interpolation\"\"\"\n",
    "    inv_affine = np.linalg.inv(affine)\n",
    "    homogeneous = np.column_stack([points, np.ones(len(points))])\n",
    "    voxel_coords = (inv_affine @ homogeneous.T)[:3, :]\n",
    "    return map_coordinates(volume.get_fdata(), voxel_coords, order=1, mode='constant', cval=0.0)\n",
    "\n",
    "def generate_layer_intensity_profile(vol, layer_type, path_surf_norm, path_surf_coords, \n",
    "                                     save_path=None, sort_by_ap=True, spacing_mm=0.12,\n",
    "                                     dist_max_mm=2, clim_max=3, cmap='RdBu_r', do_diff=False, fontsize = 9, dist_method=0):\n",
    "                                     \n",
    "    \"\"\"Generate and plot intensity profiles at varying distances from cortical surface\"\"\"\n",
    "    \n",
    "    # Load surface data\n",
    "    surf_norm = nib.load(path_surf_norm)\n",
    "    surf_coords = nib.load(path_surf_coords)\n",
    "    \n",
    "    # Extract coordinates and normals\n",
    "    norm_xyz = np.array([surf_norm.darrays[i].data for i in range(3)])\n",
    "    surf_xyz = np.array([surf_coords.darrays[i].data for i in range(3)])\n",
    "\n",
    "    if dist_method == 0:\n",
    "        #method 1 \n",
    "        #calculate half voxel up (spacing mm/2) and down (spacing mm/2) from the surface along the surfarce normal \n",
    "        dist_array = np.flipud(np.concatenate([-np.arange(spacing_mm/2, dist_max_mm, spacing_mm)[::-1], \n",
    "                                            np.arange(spacing_mm/2, dist_max_mm, spacing_mm)]))\n",
    "    elif dist_method == 1:\n",
    "        #method 2 \n",
    "        #calculate full voxel length along the surface normal\n",
    "        dist_array = np.flipud(np.concatenate([-np.arange(spacing_mm, dist_max_mm, spacing_mm)[::-1], [0], \n",
    "                                            np.arange(spacing_mm, dist_max_mm, spacing_mm)]))\n",
    "    \n",
    "    # Generate sampling points at different distances\n",
    "    all_values = []\n",
    "    for dist in dist_array:\n",
    "        sample_points = surf_xyz.T + dist * norm_xyz.T\n",
    "        values = sample_at_points(vol, sample_points, vol.affine)\n",
    "        all_values.append(values)\n",
    "    \n",
    "    all_values = np.array(all_values)\n",
    "    \n",
    "    # Sort by anterior-posterior if requested\n",
    "    ap_order = None\n",
    "    if sort_by_ap:\n",
    "        ap_coords = surf_xyz[1, :]  # Y coordinate for AP ordering\n",
    "        ap_order = np.argsort(ap_coords)\n",
    "        all_values = all_values[:, ap_order]\n",
    "    \n",
    "    return all_values, dist_array, ap_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d30722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for BigBrain\n",
    "vol_path = '/Users/dennis.jungchildmind.org/Desktop/BigBrain/HistologicalSpaceData/full16_100um_optbal.nii'#use the highest resolution volume \n",
    "surface_path = '/Users/dennis.jungchildmind.org/Desktop/BigBrain/PlosBiology2020gii/'\n",
    "\n",
    "#make these surfnorm and coord files using the calculate_surface_normal_and_coordinates.py script\n",
    "#or you can just do by workbench command\n",
    "\n",
    "save_path_subject = '/Users/dennis.jungchildmind.org/Desktop/BigBrain/PlosBiology2020gii/'\n",
    "\n",
    "hemi = 'lh'\n",
    "layer_type = 'layer6'\n",
    "inf_surface_lh = f'surfgii/{layer_type}_left_327680.surf.gii'# layer3 boundary is equivalent to the inf surface of ex vivo data    \n",
    "inf_surface_rh = f'surfgii/{layer_type}_right_327680.surf.gii'\n",
    "inf_surfnorm_lh = f'surfnorms/{layer_type}_left_327680.surfnorm.func.gii'\n",
    "inf_surfnorm_rh = f'surfnorms/{layer_type}_right_327680.surfnorm.func.gii'\n",
    "inf_coord_lh = f'surfnorms/{layer_type}_left_327680.coord.func.gii'\n",
    "inf_coord_rh = f'surfnorms/{layer_type}_right_327680.coord.func.gii'\n",
    "\n",
    "#params for the mainscript\n",
    "params = {'sort_by_ap': False, 'spacing_mm': 0.12, 'dist_max_mm': 2.0, 'clim_max': 3, 'do_diff':True, 'dist_method':0, 'fontsize': 8}\n",
    "\n",
    "\n",
    "vol = nib.load(vol_path)\n",
    "# Check if required surface files exist\n",
    "\n",
    "\n",
    "if hemi == 'lh':\n",
    "    surf_norm_path = os.path.join(surface_path, inf_surfnorm_lh)\n",
    "    surf_coord_path = os.path.join(surface_path, inf_coord_lh)\n",
    "elif hemi == 'rh':\n",
    "    surf_norm_path = os.path.join(surface_path, inf_surfnorm_rh)\n",
    "    surf_coord_path = os.path.join(surface_path, inf_coord_rh)\n",
    "else:\n",
    "    print(f\"Warning: {hemi} not found, skipping {layer_type}\")\n",
    "    exit()\n",
    "\n",
    "if not os.path.exists(surf_norm_path):\n",
    "    print(f\"Warning: {surf_norm_path} not found, skipping {layer_type}\")\n",
    "\n",
    "if not os.path.exists(surf_coord_path):\n",
    "    print(f\"Warning: {surf_coord_path} not found, skipping {layer_type}\")\n",
    "\n",
    "    \n",
    "print(f\"Processing layer: {layer_type}\")\n",
    "#calculate intensity profileS\n",
    "all_values, dist_array, ap_order = generate_layer_intensity_profile(\n",
    "    vol, layer_type,\n",
    "    surf_norm_path,\n",
    "    surf_coord_path,\n",
    "    save_path_subject, **params\n",
    ")\n",
    "\n",
    "#save all_values, dist_array, ap_order as npz \n",
    "#np.savez(f'{save_path_subject}/bigbrain_{hemi}_{layer_type}_{int(params[\"spacing_mm\"]*1000)}um_method{int(params[\"dist_method\"])}_manual_raw_intensity.npz', all_values=all_values, dist_array=dist_array, ap_order=ap_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2d621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e96d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT ALL_VALUES using functions from the context\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Configuration for plotting\n",
    "fontsize = 8\n",
    "percentil_low = 20\n",
    "percentil_high = 80\n",
    "cmap = 'plasma'\n",
    "data_types = ['raw', 'raw_zscore', 'diff', 'diff_zscore']\n",
    "\n",
    "def load_and_process_data_from_arrays(all_values, dist_array, sorted_order=None):\n",
    "    \"\"\"Process data arrays and compute processed versions (diff, zscore) with NaN handling.\"\"\"\n",
    "    \n",
    "    # Use provided sorted order or compute new one\n",
    "    if sorted_order is None:\n",
    "        # Use nanmean for sorting to handle NaN values\n",
    "        sorted_order = np.argsort(np.nanmean(all_values, axis=0))\n",
    "    \n",
    "    # Extract and sort raw values\n",
    "    raw = all_values[:, sorted_order]\n",
    "    \n",
    "    # Compute processed versions with NaN handling\n",
    "    # For zscore, use nanmean and nanstd\n",
    "    raw_mean = np.nanmean(raw, axis=0, keepdims=True)\n",
    "    raw_std = np.nanstd(raw, axis=0, keepdims=True)\n",
    "    raw_std[raw_std == 0] = 1  # Avoid division by zero\n",
    "    raw_zscore = (raw - raw_mean) / raw_std\n",
    "    \n",
    "    # For diff, use np.diff which preserves NaN values\n",
    "    diff = np.diff(raw, axis=0)\n",
    "    diff_mean = np.nanmean(diff, axis=0, keepdims=True)\n",
    "    diff_std = np.nanstd(diff, axis=0, keepdims=True)\n",
    "    diff_std[diff_std == 0] = 1  # Avoid division by zero\n",
    "    diff_zscore = (diff - diff_mean) / diff_std\n",
    "    \n",
    "    return {\n",
    "        'raw': raw,\n",
    "        'raw_zscore': raw_zscore,\n",
    "        'diff': diff,\n",
    "        'diff_zscore': diff_zscore,\n",
    "        'sorted_order': sorted_order\n",
    "    }\n",
    "\n",
    "def set_colorbar_limits(data, data_type):\n",
    "    \"\"\"Set appropriate colorbar limits based on data type with NaN handling.\"\"\"\n",
    "    # Use nanpercentile to handle NaN values\n",
    "    if data_type == 'raw':\n",
    "        return np.nanpercentile(data, percentil_low), np.nanpercentile(data, percentil_high)\n",
    "    elif data_type in ['diff','diff_zscore','raw_zscore']:\n",
    "        p_low, p_high = np.nanpercentile(data, percentil_low), np.nanpercentile(data, percentil_high)\n",
    "        return p_low, p_high\n",
    "\n",
    "def setup_colorbar(im, ax, data_type, vmin, vmax):\n",
    "    \"\"\"Setup colorbar with appropriate ticks and labels.\"\"\"\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    \n",
    "    if data_type in ['diff', 'diff_zscore']:\n",
    "        cbar.set_ticks([vmin, 0, vmax])\n",
    "        cbar.set_ticklabels([f'{vmin:.2f}', '0', f'{vmax:.2f}'])\n",
    "    \n",
    "    return cbar\n",
    "\n",
    "def create_subplot(ax, data, title, data_type, plot_dist_values):\n",
    "    \"\"\"Create a single subplot with proper formatting and NaN handling.\"\"\"\n",
    "    # Create masked array to handle NaN values in visualization\n",
    "    masked_data = np.ma.masked_invalid(data)\n",
    "    #remove 65536 from the data\n",
    "    masked_data = np.delete(masked_data, 65535, axis=1)\n",
    "    im = ax.imshow(masked_data, aspect='auto', \n",
    "                   extent=[0, data.shape[1], plot_dist_values[-1], plot_dist_values[0]], \n",
    "                   cmap=cmap)\n",
    "    \n",
    "    vmin, vmax = set_colorbar_limits(data, data_type)\n",
    "    \n",
    "    # Handle case where vmin or vmax might be NaN\n",
    "    if np.isnan(vmin) or np.isnan(vmax):\n",
    "        print(f\"Warning: NaN values in colorbar limits for {title}, using data min/max\")\n",
    "        vmin, vmax = np.nanmin(data), np.nanmax(data)\n",
    "\n",
    "    im.set_clim(vmin, vmax)\n",
    "    \n",
    "    setup_colorbar(im, ax, data_type, vmin, vmax)\n",
    "    \n",
    "    ax.set_xlabel('Vertices (ordered by column mean)', fontsize=fontsize+1)\n",
    "    ax.set_ylabel('Rel. Inf Surf (mm)', fontsize=fontsize)\n",
    "    ax.set_title(title, fontsize=fontsize+1, fontweight='bold')\n",
    "    \n",
    "    return im\n",
    "\n",
    "# Process the data\n",
    "processed_data = load_and_process_data_from_arrays(all_values, dist_array)\n",
    "\n",
    "# Create combined 2x2 figure\n",
    "combined_fig, axes = plt.subplots(2, 2, figsize=(12, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, data_type in enumerate(data_types):\n",
    "    data = processed_data[data_type]\n",
    "    create_subplot(axes[i], data, f'{data_type}', data_type, dist_array)\n",
    "\n",
    "plt.suptitle(f'BigBrain {hemi} {layer_type} - All Data Types', fontsize=fontsize+2, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca9941",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dist_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abfd77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dist value average of every two values \n",
    "dist_array_between = (dist_array[1:] + dist_array[:-1]) / 2\n",
    "print(dist_array_between)\n",
    "\n",
    "data_type='raw'\n",
    "data = processed_data[data_type]\n",
    "\n",
    "if data_type == 'raw':\n",
    "    xval = dist_array\n",
    "elif data_type ==  'zscore':\n",
    "    xval = dist_array_between\n",
    "\n",
    "# Create continuous errorbar using fill_between\n",
    "mean_values = np.median(data, axis=1)\n",
    "std_values = np.std(data, axis=1)\n",
    "sem_values = std_values / np.sqrt(data.shape[1]-1)\n",
    "\n",
    "plt.plot(xval, mean_values, 'b-', linewidth=2)\n",
    "plt.fill_between(xval, mean_values - std_values, mean_values + std_values, \n",
    "                 alpha=0.3, color='blue')\n",
    "                 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "niwrap3912",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
