{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48bb1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import ants\n",
    "from ants.plotting import plot\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622792d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fooof'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msignal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m resample\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaspy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfooof\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FOOOF \n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mtspectrumc\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculate_source_1over4exp\u001b[39m(\n\u001b[32m     15\u001b[39m     subject, \n\u001b[32m     16\u001b[39m     session, \n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     fdownsample=\u001b[32m200\u001b[39m,\n\u001b[32m     24\u001b[39m ):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'fooof'"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import io as sio\n",
    "from scipy.signal import resample\n",
    "import yaspy\n",
    "from fooof import FOOOF \n",
    "from utils import mtspectrumc\n",
    "\n",
    "def calculate_source_1over4exp(\n",
    "    subject, \n",
    "    session, \n",
    "    session_num, \n",
    "    basedir_preproc,\n",
    "    basedir_meg,\n",
    "    atlas_path,\n",
    "    save_path=None,\n",
    "    n_jobs=24,\n",
    "    fdownsample=200,\n",
    "):\n",
    "    \"\"\"\n",
    "    Main function to run subcortical parcellation analysis for a single subject/session.\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup atlas files\n",
    "    atlas_lh_file = os.path.join(atlas_path, 'L.Schaefer2018_400Parcels_7Networks_order_4k_fslr.label.gii')\n",
    "    atlas_rh_file = os.path.join(atlas_path, 'R.Schaefer2018_400Parcels_7Networks_order_4k_fslr.label.gii')\n",
    "    atlas_lh = nib.load(atlas_lh_file)\n",
    "    atlas_rh = nib.load(atlas_rh_file)\n",
    "    atlas_both_hemi = np.concatenate((atlas_lh.darrays[0].data, atlas_rh.darrays[0].data))\n",
    "    lh_label = np.unique(atlas_lh.darrays[0].data)\n",
    "    rh_label = np.unique(atlas_rh.darrays[0].data)\n",
    "    total_label = np.concatenate((lh_label[1:], rh_label[1:]))\n",
    "\n",
    "    # File paths\n",
    "    icaclass_dir = os.path.join(\n",
    "        basedir_meg, subject, 'MEG', session, 'icaclass', \n",
    "        f'{subject}_MEG_{session_num}-{session}_icaclass.mat'\n",
    "    )\n",
    "    icaclass_vs_dir = os.path.join(\n",
    "        basedir_meg, subject, 'MEG', session, 'icaclass', \n",
    "        f'{subject}_MEG_{session_num}-{session}_icaclass_vs.mat'\n",
    "    )\n",
    "    icamne_dir = os.path.join(\n",
    "        basedir_preproc, subject, 'MEG', session, 'icamne', \n",
    "        f'{subject}_MEG_{session_num}-{session}_icamne.mat'\n",
    "    )\n",
    "    if save_path is None:\n",
    "        save_path = os.path.join(basedir_preproc, subject, 'MEG', 'source_timeseries')\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    save_filename = f'source_timeseries_{session_num}_{session}.pkl'\n",
    "    save_filepath = os.path.join(save_path, save_filename)\n",
    "    print(f\"Output will be saved to: {save_filepath}\")\n",
    "\n",
    "    def load_mat_file(filepath):\n",
    "        print(f\"Loading {os.path.basename(filepath)}...\")\n",
    "        try:\n",
    "            data = sio.loadmat(filepath, struct_as_record=False, squeeze_me=True)\n",
    "            print(f\"  ✓ Loaded with scipy.io\")\n",
    "            return data, 'scipy'\n",
    "        except NotImplementedError:\n",
    "            data = h5py.File(filepath, 'r')\n",
    "            print(f\"  ✓ Loaded with h5py\")\n",
    "            return data, 'h5py'\n",
    "\n",
    "    def resample_trial(trial_data, original_fs, target_fs):\n",
    "        n_channels, n_samples = trial_data.shape\n",
    "        n_samples_new = int(np.round(n_samples * target_fs / original_fs))\n",
    "        trial_resampled = resample(trial_data, n_samples_new, axis=1)\n",
    "        return trial_resampled\n",
    "\n",
    "    # Load data\n",
    "    print(\"=\"*60)\n",
    "    print(\"LOADING DATA FILES\")\n",
    "    print(\"=\"*60)\n",
    "    icaclass_data, icaclass_type = load_mat_file(icaclass_dir)\n",
    "    icaclass_vs_data, icaclass_vs_type = load_mat_file(icaclass_vs_dir)\n",
    "    icamne_data, icamne_type = load_mat_file(icamne_dir)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXTRACTING FIELDS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # ============ Extract icamne data (source signals)\n",
    "    if icamne_type == 'scipy':\n",
    "        source_sig = list(icamne_data['source'].avg.mom)\n",
    "    else:\n",
    "        mom_refs = icamne_data['source']['avg']['mom'][:]\n",
    "        source_sig = []\n",
    "        for ref in mom_refs.flatten():\n",
    "            data = icamne_data[ref][:].T\n",
    "            source_sig.append(data)\n",
    "    pos = icamne_data['source']['pos']\n",
    "    tri = icamne_data['source']['tri']\n",
    "\n",
    "    print(f\"\\nSource data:\")\n",
    "    print(f\"  Number of source locations: {len(source_sig)}\")\n",
    "    print(f\"  First source shape: {source_sig[0].shape} (expected: 3 x n_ICs)\")\n",
    "\n",
    "    # ============ Extract icaclass data\n",
    "    if icaclass_type == 'scipy':\n",
    "        comp_class = icaclass_data['comp_class']\n",
    "        fsample = float(comp_class.fsample)\n",
    "        # Access 'class' field robustly\n",
    "        if hasattr(comp_class, 'class_'):\n",
    "            class_struct = comp_class.class_\n",
    "        elif hasattr(comp_class, '_class'):\n",
    "            class_struct = comp_class._class\n",
    "        else:\n",
    "            class_struct = comp_class.__dict__.get('class', None)\n",
    "            if class_struct is None:\n",
    "                for field_name in getattr(comp_class, '_fieldnames', []):\n",
    "                    if 'class' in field_name.lower():\n",
    "                        class_struct = getattr(comp_class, field_name)\n",
    "                        break\n",
    "        brainic_index = np.array(class_struct.brain_ic).flatten().astype(int) - 1\n",
    "        ica_trial_sig_full = list(comp_class.trial)\n",
    "    else:\n",
    "        comp_class = icaclass_data['comp_class']\n",
    "        fsample = float(comp_class['fsample'][0, 0])\n",
    "        brainic_ref = comp_class['class']['brain_ic'][0, 0]\n",
    "        brainic_index = icaclass_data[brainic_ref][:].flatten().astype(int) - 1\n",
    "        trial_refs = comp_class['trial'][:].flatten()\n",
    "        ica_trial_sig_full = [icaclass_data[ref][:].T for ref in trial_refs]\n",
    "\n",
    "    print(f\"\\nICA class data:\")\n",
    "    print(f\"  Sample rate: {fsample} Hz\")\n",
    "    print(f\"  Number of brain ICs: {len(brainic_index)}\")\n",
    "    print(f\"  Brain IC indices: {brainic_index}\")\n",
    "    print(f\"  Number of trials: {len(ica_trial_sig_full)}\")\n",
    "    for i, trial in enumerate(ica_trial_sig_full):\n",
    "        print(f\"    Trial {i+1} shape: {trial.shape} (expected: n_ICs x n_timepoints)\")\n",
    "\n",
    "    # ============ DOWNSAMPLE ICA TRIAL DATA\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DOWNSAMPLING ICA TRIAL DATA\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Original sampling rate: {fsample} Hz\")\n",
    "    print(f\"Target sampling rate: {fdownsample} Hz\")\n",
    "    print(f\"Downsampling ratio: {fsample/fdownsample:.2f}x\")\n",
    "\n",
    "    ica_trial_sig_downsampled = []\n",
    "    for i, trial in enumerate(ica_trial_sig_full):\n",
    "        trial_ds = resample_trial(trial, fsample, fdownsample)\n",
    "        ica_trial_sig_downsampled.append(trial_ds)\n",
    "        print(f\"  Trial {i+1}: {trial.shape} -> {trial_ds.shape}\")\n",
    "\n",
    "    ica_trial_sig_full = ica_trial_sig_downsampled\n",
    "    fsample = fdownsample  # Update sampling rate\n",
    "\n",
    "    # ============ Extract icaclass_vs data\n",
    "    if icaclass_vs_type == 'scipy':\n",
    "        comp_class_vs = icaclass_vs_data['comp_class']\n",
    "        fsample_vs = float(comp_class_vs.fsample)\n",
    "        if hasattr(comp_class_vs, 'class_'):\n",
    "            class_struct_vs = comp_class_vs.class_\n",
    "        elif hasattr(comp_class_vs, '_class'):\n",
    "            class_struct_vs = comp_class_vs._class\n",
    "        else:\n",
    "            class_struct_vs = comp_class_vs.__dict__.get('class', None)\n",
    "            if class_struct_vs is None:\n",
    "                for field_name in getattr(comp_class_vs, '_fieldnames', []):\n",
    "                    if 'class' in field_name.lower():\n",
    "                        class_struct_vs = getattr(comp_class_vs, field_name)\n",
    "                        break\n",
    "        brainic_index_vs = np.array(class_struct_vs.brain_ic).flatten().astype(int) - 1\n",
    "        ica_trial_sig_vs_full = list(comp_class_vs.trial)\n",
    "    else:\n",
    "        comp_class_vs = icaclass_vs_data['comp_class']\n",
    "        fsample_vs = float(comp_class_vs['fsample'][0, 0])\n",
    "        brainic_ref_vs = comp_class_vs['class']['brain_ic'][0, 0]\n",
    "        brainic_index_vs = icaclass_vs_data[brainic_ref_vs][:].flatten().astype(int) - 1\n",
    "        trial_refs_vs = comp_class_vs['trial'][:].flatten()\n",
    "        ica_trial_sig_vs_full = [icaclass_vs_data[ref][:].T for ref in trial_refs_vs]\n",
    "\n",
    "    print(f\"\\nICA class VS data:\")\n",
    "    print(f\"  Sample rate: {fsample_vs} Hz\")\n",
    "    print(f\"  Number of brain ICs: {len(brainic_index_vs)}\")\n",
    "\n",
    "    # Downsample VS trials\n",
    "    print(\"\\nDownsampling VS trial data...\")\n",
    "    ica_trial_sig_vs_downsampled = []\n",
    "    for i, trial in enumerate(ica_trial_sig_vs_full):\n",
    "        trial_ds = resample_trial(trial, fsample_vs, fdownsample)\n",
    "        ica_trial_sig_vs_downsampled.append(trial_ds)\n",
    "        print(f\"  VS Trial {i+1}: {trial.shape} -> {trial_ds.shape}\")\n",
    "\n",
    "    ica_trial_sig_vs_full = ica_trial_sig_vs_downsampled\n",
    "\n",
    "    # ============ Select brain components from source signals\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SELECTING BRAIN COMPONENTS\")\n",
    "    print(\"=\"*60)\n",
    "    source_sig_brain = []\n",
    "    for i, src in enumerate(source_sig):\n",
    "        if src.shape[1] >= max(brainic_index) + 1:\n",
    "            source_sig_brain.append(src[:, brainic_index])\n",
    "        elif src.shape[0] >= max(brainic_index) + 1:\n",
    "            source_sig_brain.append(src[brainic_index, :].T)\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot select brain ICs from source {i} with shape {src.shape}\")\n",
    "\n",
    "    source_sig = source_sig_brain\n",
    "    print(f\"Source signals after selection:\")\n",
    "    print(f\"  First source shape: {source_sig[0].shape} (expected: 3 x n_brain_ICs)\")\n",
    "\n",
    "    # ============ Select brain components from ICA trial signals\n",
    "    ica_trial_sig = []\n",
    "    for i, trial in enumerate(ica_trial_sig_full):\n",
    "        if trial.shape[0] >= max(brainic_index) + 1:\n",
    "            ica_trial_sig.append(trial[brainic_index, :])\n",
    "        elif trial.shape[1] >= max(brainic_index) + 1:\n",
    "            ica_trial_sig.append(trial[:, brainic_index].T)\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot select brain ICs from trial {i} with shape {trial.shape}\")\n",
    "\n",
    "    print(f\"Trial signals after selection:\")\n",
    "    for i, trial in enumerate(ica_trial_sig):\n",
    "        print(f\"  Trial {i+1} shape: {trial.shape} (expected: n_brain_ICs x n_timepoints)\")\n",
    "\n",
    "    # Same for icaclass_vs\n",
    "    ica_trial_sig_vs = []\n",
    "    for i, trial in enumerate(ica_trial_sig_vs_full):\n",
    "        if trial.shape[0] >= max(brainic_index_vs) + 1:\n",
    "            ica_trial_sig_vs.append(trial[brainic_index_vs, :])\n",
    "        elif trial.shape[1] >= max(brainic_index_vs) + 1:\n",
    "            ica_trial_sig_vs.append(trial[:, brainic_index_vs].T)\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot select brain ICs from VS trial {i} with shape {trial.shape}\")\n",
    "\n",
    "    # ============ Create source level trial signals\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CREATING SOURCE LEVEL TRIAL SIGNALS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    source_level_trial_sig = []\n",
    "    for trl_index in range(len(ica_trial_sig)):\n",
    "        trial_data = []\n",
    "        for src_idx, src in enumerate(source_sig):\n",
    "            result = src @ ica_trial_sig[trl_index]\n",
    "            trial_data.append(result)\n",
    "            if trl_index == 0 and src_idx == 0:\n",
    "                print(f\"Matrix multiplication check:\")\n",
    "                print(f\"  Source: {src.shape} @ Trial: {ica_trial_sig[trl_index].shape} = Result: {result.shape}\")\n",
    "        source_level_trial_sig.append(trial_data)\n",
    "        print(f\"  Trial {trl_index+1}/{len(ica_trial_sig)} complete ({len(trial_data)} sources)\")\n",
    "\n",
    "    print(f\"\\nSource-level trial signals created:\")\n",
    "    print(f\"  Number of trials: {len(source_level_trial_sig)}\")\n",
    "    print(f\"  Sources per trial: {len(source_level_trial_sig[0])}\")\n",
    "    print(f\"  First source shape: {source_level_trial_sig[0][0].shape} (expected: 3 x n_timepoints)\")\n",
    "\n",
    "    # (1) calculate power spectrum first \n",
    "    def calculate_power_spectrum(voxel_data, params, freq_range):\n",
    "        S, f, Serr = mtspectrumc(voxel_data, params)\n",
    "        return S, f\n",
    "\n",
    "    # Setup parameters\n",
    "    freq_range = [1, 50]\n",
    "    k = 0\n",
    "    voxel_data_list = source_level_trial_sig[k]\n",
    "    n_voxels = len(voxel_data_list)\n",
    "\n",
    "    params = {\n",
    "        'tapers': [4,7],\n",
    "        'pad': 0,\n",
    "        'Fs': fdownsample,  # will set below\n",
    "        'fpass': [1, 100],\n",
    "        'trialave': True,\n",
    "    }\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=5)(\n",
    "        delayed(calculate_power_spectrum)(voxel_data_list[i], params, freq_range)\n",
    "        for i in range(n_voxels)\n",
    "    )\n",
    "    S_list, f_list = zip(*results)\n",
    "\n",
    "    # (2) then parcellate the power spectrum\n",
    "    tmp_dat = np.array(S_list)\n",
    "    atlas_both_hemi = np.concatenate((atlas_lh.darrays[0].data, atlas_rh.darrays[0].data))\n",
    "    lh_label = np.unique(atlas_lh.darrays[0].data)\n",
    "    rh_label = np.unique(atlas_rh.darrays[0].data)\n",
    "    total_label = np.concatenate((lh_label[1:], rh_label[1:]))\n",
    "\n",
    "    parcel_data = []\n",
    "    for i, label in enumerate(total_label):\n",
    "        print(f'{i}: {label}')\n",
    "        indx = np.where(atlas_both_hemi == label)[0]\n",
    "        if sum(indx) > 0:\n",
    "            dat_indx = tmp_dat[indx]\n",
    "            dat_indx_mean = np.mean(dat_indx, axis=0)\n",
    "            parcel_data.append(dat_indx_mean)\n",
    "\n",
    "    # (3) Calculate FOOOF\n",
    "    parcel_len = len(parcel_data)\n",
    "    print(parcel_len)\n",
    "    freq_range = [1, 50]\n",
    "\n",
    "    def process_voxel(f, voxel_data, freq_range):\n",
    "        fm = FOOOF()\n",
    "        fm.fit(f, voxel_data, freq_range)\n",
    "        exp = fm.get_params('aperiodic_params', 'exponent')\n",
    "        offset = fm.get_params('aperiodic_params', 'offset')\n",
    "        error = fm.error_\n",
    "        r2 = fm.r_squared_\n",
    "        return exp, offset, error, r2\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs, verbose=5)(\n",
    "        delayed(process_voxel)(f_list[0], parcel_data[i], freq_range)\n",
    "        for i in range(parcel_len)\n",
    "    )\n",
    "\n",
    "    exp_list, offset_list, error_list, r2_list = zip(*results)\n",
    "    exp_list = list(exp_list)\n",
    "    offset_list = list(offset_list)\n",
    "    error_list = list(error_list)\n",
    "    r2_list = list(r2_list)\n",
    "\n",
    "    # Save important outputs as a pickle for further downstream steps:\n",
    "    output_data = {\n",
    "        'exp_list': exp_list,\n",
    "        'offset_list': offset_list,\n",
    "        'error_list': error_list,\n",
    "        'r2_list': r2_list,\n",
    "        'parcel_data': parcel_data,\n",
    "        'f': f_list[0],\n",
    "        'atlas_labels': total_label,\n",
    "        'atlas_path': atlas_path,\n",
    "        'subject': subject,\n",
    "        'session': session,\n",
    "        'session_num': session_num\n",
    "    }\n",
    "    with open(save_filepath, 'wb') as f:\n",
    "        pickle.dump(output_data, f)\n",
    "    \n",
    "    print(f\"Results saved to {save_filepath}\")\n",
    "    return output_data\n",
    "\n",
    "# Example usage for SLURM (adapt params as needed for your run script):\n",
    "# output = calculate_source_1overfexp(\n",
    "#     subject='100307',\n",
    "#     session='Restin',\n",
    "#     session_num=3,\n",
    "#     basedir_preproc='/data4/BrainED_project/shared/HCP_MEG_PREPROC',\n",
    "#     basedir_meg='/data4/BrainED_project/shared/HCP_MEG',\n",
    "#     atlas_path='/data4/BrainED_project/djung/parcellation/4k_fslr',\n",
    "#     save_path=None,\n",
    "#     n_jobs=24,\n",
    "#     fdownsample=200,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e8e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read mapped image\n",
    "mapped_image_path = '/Users/dennis.jungchildmind.org/Desktop/subcortical_test/I38_new_confidence/warped_template.nii.gz'\n",
    "mapped_image = ants.image_read(mapped_image_path)\n",
    "print(mapped_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1884379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_image_np = mapped_image.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342858fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mapped_image_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce1291",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(mapped_image_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_path = '/Users/dennis.jungchildmind.org/Desktop/subcortical_test/I38_new_confidence/orig_img_resampled.nii'\n",
    "original_image = ants.image_read(original_image_path)\n",
    "print(original_image)\n",
    "plot(original_image,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f83bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = nib.load(template_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dc88e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "print(tmp.get_fdata().shape)\n",
    "print(np.unique(tmp.get_fdata()).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d511d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_path = '/Users/dennis.jungchildmind.org/Desktop/atlas/mni_icbm152_nlin_asym_09c_nifti/mni_icbm152_t1_tal_nlin_asym_09c.nii'\n",
    "headmask_path = '/Users/dennis.jungchildmind.org/Desktop/atlas/mni_icbm152_nlin_asym_09c_nifti/mni_icbm152_t1_tal_nlin_asym_09c_mask.nii'#only has t\n",
    "template = ants.image_read(template_path)\n",
    "headmask = ants.image_read(headmask_path)\n",
    "masked_template = ants.mask_image(template, headmask,level=1,binarize=False)#this removes the skull right away\n",
    "# Get numpy array\n",
    "data = masked_template.numpy()\n",
    "\n",
    "# Create left hemisphere mask\n",
    "# In MNI space with ANTs, need to check orientation\n",
    "center_x = data.shape[0] // 2\n",
    "left_mask = np.zeros_like(data)\n",
    "left_mask[:center_x, :, :] = 1\n",
    "\n",
    "# Create ANTs image from mask\n",
    "mask_img = ants.from_numpy(left_mask, origin=masked_template.origin, \n",
    "                           spacing=masked_template.spacing, direction=masked_template.direction)\n",
    "left_hemisphere = masked_template * mask_img\n",
    "plot(left_hemisphere,axis=1)\n",
    "# Save result\n",
    "ants.image_write(left_hemisphere, 'mni_icbm152_t1_tal_nlin_asym_09c_left_hemi.nii')\n",
    "\n",
    "#do for right hemisphere\n",
    "right_mask = np.zeros_like(data)\n",
    "right_mask[center_x:, :, :] = 1\n",
    "right_hemisphere = masked_template * ants.from_numpy(right_mask, origin=masked_template.origin, \n",
    "                           spacing=masked_template.spacing, direction=masked_template.direction)\n",
    "plot(right_hemisphere,axis=1)\n",
    "ants.image_write(right_hemisphere, 'mni_icbm152_t1_tal_nlin_asym_09c_right_hemi.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define file paths\n",
    "template_path = '/Users/dennis.jungchildmind.org/Desktop/atlas/mni_icbm152_nlin_asym_09c_nifti/mni_icbm152_t2_tal_nlin_asym_09c.nii'\n",
    "headmask_path = '/Users/dennis.jungchildmind.org/Desktop/atlas/mni_icbm152_nlin_asym_09c_nifti/mni_icbm152_t1_tal_nlin_asym_09c_mask.nii'#only has t\n",
    "atlas_path = '/Users/dennis.jungchildmind.org/Desktop/subcortical_test/Schaefer2018_400Parcels_7Networks_order_Tian_Subcortex_S1_3T_MNI152NLin2009cAsym_1mm.nii.gz'\n",
    "\n",
    "# Read images\n",
    "template = ants.image_read(template_path)\n",
    "headmask = ants.image_read(headmask_path)\n",
    "atlas = ants.image_read(atlas_path)\n",
    "\n",
    "#make sure the shape of the atlas and template are the same\n",
    "if atlas.shape != template.shape:\n",
    "    print(\"The shape of the atlas and template are not the same\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"The shape of the atlas and template are the same\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc251d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_template = ants.mask_image(template, headmask,level=1,binarize=False)#this removes the skull right away\n",
    "plot(masked_template,axis=2)\n",
    "plot(atlas,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get labels from the atlas so that I can generate a mask for the left or right hemisphere\n",
    "atlas_label = atlas.numpy()\n",
    "#just manual separate of lh and rh \n",
    "# Fix: Combine hardcoded values with range for RH labels according to the comment\n",
    "rh_label = list(range(1, 9)) + list(range(217, 417))\n",
    "lh_label = list(range(9, 217))  # 9 through 216 inclusive\n",
    "\n",
    "#generate a mask for the left hemisphere\n",
    "left_hemisphere_mask = np.isin(atlas_label, lh_label)\n",
    "right_hemisphere_mask = np.isin(atlas_label, rh_label)\n",
    "# Convert to ANTs images\n",
    "# Method 1: Using from_numpy (RECOMMENDED)\n",
    "left_hemi_mask_ants = ants.from_numpy(\n",
    "    left_hemisphere_mask.astype('float32'),  # Convert bool to float\n",
    "    origin=atlas.origin,\n",
    "    spacing=atlas.spacing,\n",
    "    direction=atlas.direction\n",
    ")\n",
    "\n",
    "right_hemi_mask_ants = ants.from_numpy(\n",
    "    right_hemisphere_mask.astype('float32'),\n",
    "    origin=atlas.origin,\n",
    "    spacing=atlas.spacing,\n",
    "    direction=atlas.direction\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_template_lh = ants.mask_image(masked_template,left_hemi_mask_ants,level=1,binarize=False)\n",
    "plot(masked_template_lh,axis=2)\n",
    "masked_template_rh = ants.mask_image(masked_template,right_hemi_mask_ants,level=1,binarize=False)\n",
    "plot(masked_template_rh,axis=2)\n",
    "\n",
    "#save the masked templates\n",
    "# Save the masks\n",
    "ants.image_write(masked_template_lh, 'mni_icbm152_t2_tal_nlin_asym_09c_masked_lh_only.nii.gz')\n",
    "ants.image_write(masked_template_rh, 'mni_icbm152_t2_tal_nlin_asym_09c_masked_rh_only.nii.gz')\n",
    "\n",
    "print(f\"Left hemisphere mask: {left_hemi_mask_ants.shape}\")\n",
    "print(f\"Right hemisphere mask: {right_hemi_mask_ants.shape}\")\n",
    "print(f\"Left hemisphere voxels: {np.sum(left_hemisphere_mask)}\")\n",
    "print(f\"Right hemisphere voxels: {np.sum(right_hemisphere_mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e7dc18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c29880c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[        nan 43.17040495 45.49635934 27.22282983 20.5721383  42.28919479\n",
      " 34.69781011 42.19293438 38.51152827 26.79548571 32.63160857 10.1579598\n",
      "  4.61876665 35.47979882 19.18625484 25.7091647  29.84380739 43.03754274\n",
      " 35.33918616 56.24260294 42.04502685 58.89166708 72.24595763 27.7690414\n",
      " 64.72923622 72.03813689 44.65383935 59.05703344 82.23463442 27.44741097\n",
      " 76.18864038 80.68663779 39.36571949 66.2874954  70.74577119 79.41141228\n",
      " 31.18349471 56.60987574 47.37821486 72.60733547 79.42190782 69.0794426\n",
      " 55.19709977 70.15999031 73.00640895 76.61737237 69.86386435 73.14514234\n",
      " 42.52455668 46.98636966 27.13232676 31.0549871  30.19653251 53.59332156\n",
      " 36.19690075 40.95275916 53.59547952 40.84026802 53.68958106 55.70575286\n",
      " 59.85947819 50.75139931 57.59001885 56.9255993  52.10064949 40.96213839\n",
      " 52.44423685 62.37445128 65.68359929 55.86807572 51.96142655 51.00856329\n",
      " 54.48740379 63.47207078 66.93354088 61.78242829 65.70614992 61.65689369\n",
      " 62.24928045 68.82978459 63.96824179 67.48086643 65.08848998 70.29189027\n",
      " 68.31836877 51.47500698 58.69828416 63.62255046 61.74172744 60.16029855\n",
      " 61.14746642 63.4821289  53.66195334 50.37048451 62.4029893  55.63501999\n",
      " 65.62196069 73.73606288 73.24260207 70.22100951 72.06367265 73.67459262\n",
      " 57.3377822  54.84219438 51.14502588 64.15045765 51.17173216 56.10416736\n",
      " 49.89500043 58.9078525  58.73588482 61.30451366 59.20907034 48.35439506\n",
      " 37.52277346 49.89736778 31.66006563 44.79064456 35.85852633 46.10233371\n",
      " 46.09694444 51.4341069  69.49078544 47.58743861 39.58494991 35.94846149\n",
      " 50.76015289 47.31884783 59.87369455 67.54244966 52.02558414 51.53579489\n",
      " 72.24320897 50.82797229 85.72663395 58.84362546 55.1100067  44.09220828\n",
      " 59.34381325 45.78712342 62.17491794 53.144115   35.12698727 69.97647269\n",
      " 67.34898052 66.62939352 65.40689968 63.61285351 58.62450122 62.14266791\n",
      " 74.02025388 76.73502415 66.43680532 74.22681368 78.68667899 66.96674906\n",
      " 56.76589974 48.11365882 66.04291896 45.41250673 71.32011579 64.97222639\n",
      " 33.88799938 23.44552732 62.49124376 60.54870955 59.56626162 59.6016334\n",
      " 53.43821241 53.96559151 54.96552185 44.8895944  52.81150868 54.30235076\n",
      " 49.56917174 59.06752989 56.43434542 72.12390157 63.9558764  64.06195558\n",
      " 73.0449035  70.11247494 53.69947855 64.96464222 76.46720674 56.2674238\n",
      " 65.19370575 80.30654829 61.29445389 78.8133287  63.72653726 58.42143198\n",
      " 87.17337703 54.5889691  73.93861645 80.99924739 75.06416165 62.25265796\n",
      " 64.38646461 77.11054149 69.93382034 59.18719573 63.70177281 61.23054681\n",
      " 69.968614   65.63922161 33.76228359 44.68662811 37.99843689 27.93278238\n",
      " 57.72467156 48.3667671  36.36406257 35.4101813  31.81747047 61.46577594\n",
      " 49.00027298 56.2719522  49.30922287 62.80626167 75.92716034 51.77571998\n",
      " 67.02059111 38.41377147 78.33977078 78.26073125 86.30915199 58.3581993\n",
      " 46.49360361 87.68137242 39.17895952 76.80237693 76.07231285 37.18756088\n",
      " 84.5891591  58.44779168 52.2752519  87.80661304 81.65071094 80.54002177\n",
      " 56.14323807 65.97329028 80.032778   78.93641668 70.38246745 80.14554025\n",
      " 78.13466271 68.4576911  73.05290884 64.11976105 50.42134275 50.23417154\n",
      " 45.99534322 71.27973744 76.77880748 53.35924356 54.25350466 61.39997402\n",
      " 72.41984951 60.68214151 73.42786092 79.00510291 74.26100566 75.82509253\n",
      " 70.82259687 73.6912252  40.63567816 76.18906564 69.64117915 78.07698781\n",
      " 48.80064735 71.80651603 74.16036784 72.8781923  74.91617251 71.18837357\n",
      " 54.98159937 71.02640367 68.83160152 68.45110752 70.64714228 74.47843617\n",
      " 70.14843535 78.31128589 68.030855   72.17623409 75.08946326 72.59230539\n",
      " 79.46527591 74.72715253 83.74817228 70.60795794 77.8187821  80.84786586\n",
      " 72.4428317  67.46595633 77.45120043 66.49621027 75.39337836 66.97855408\n",
      " 73.27468201 72.78894491 77.03250867 66.74186964 78.14282837 78.20548784\n",
      " 70.14615961 61.3356778  69.56454368 67.83815087 75.23962406 66.65461223\n",
      " 76.5356166  72.13181298 72.9170481  80.10588209 81.01200012 74.0169699\n",
      " 60.68178999 58.77354831 53.02451917 52.7001474  62.89702727 55.0633248\n",
      " 64.80214783 71.65465095 79.831427   50.38453568 45.56223412 45.00432918\n",
      " 61.0920324  57.35986747 50.66657594 65.07760356 73.13903033 56.07319594\n",
      " 59.63676992 74.97341036 73.31968734 52.11058826 87.1817729  63.55952382\n",
      " 76.83931863 74.18109264 63.31174488 62.58313156 69.84200619 47.04995529\n",
      " 82.95940891 81.36829097 80.70760517 80.24422937 74.76444405 76.14744986\n",
      " 77.92142361 79.63105716 61.52755968 85.56350203 88.63166146 87.21854996\n",
      " 83.87435754 83.75077689 78.02729792 71.23055619 83.55116226 78.02871184\n",
      " 64.08951294 78.73365204 76.70528587 74.12160126 74.85132943 68.34011061\n",
      " 67.12675003 61.42541858 27.70192307 34.55915597 59.39479715 65.02227989\n",
      " 71.82623936 76.28069853 75.03232669 76.18527418 82.16011492 77.48120021\n",
      " 78.20265389 73.43189463 70.52952253 75.16861696 61.50300075 76.5959418\n",
      " 63.08538598 66.50841754 75.41905646 78.9980696  77.08913091 64.15505944\n",
      " 88.62519868 63.40119964 75.48693207 89.58722547 47.64402032 82.10378831\n",
      " 82.22048818 73.63677249 72.60139878 78.36726608 71.77159338 72.0422794\n",
      " 43.66248449 32.76837085 56.47318973 40.43280479 53.57840989 38.42948347\n",
      " 33.62952372 48.65496502 52.48520164]\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      " 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n",
      " 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n",
      " 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n",
      " 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n",
      " 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195.\n",
      " 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209.\n",
      " 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223.\n",
      " 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237.\n",
      " 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251.\n",
      " 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265.\n",
      " 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279.\n",
      " 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293.\n",
      " 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307.\n",
      " 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321.\n",
      " 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335.\n",
      " 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349.\n",
      " 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363.\n",
      " 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377.\n",
      " 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391.\n",
      " 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405.\n",
      " 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416.]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(dists_dict['dist_lh']))\n",
    "print(np.array(dists_dict['label']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "niwrap3912",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
